<html>
<head>
<title>cs284-p1</title>
<link href="css/style.css" type="text/css" rel="stylesheet" media="all">
<link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">

<!-- js -->
<script src="js/jquery.min.js"></script>
<script src="js/modernizr.custom.js"></script>
<!-- //js -->	
<!-- start-smoth-scrolling-->
<script type="text/javascript" src="js/move-top.js"></script>
<script type="text/javascript" src="js/easing.js"></script>	
<script type="text/javascript" src="js/modernizr.custom.53451.js"></script>
<script type="text/javascript">
		jQuery(document).ready(function($) {
			$(".scroll").click(function(event){		
				event.preventDefault();
				$('html,body').animate({scrollTop:$(this.hash).offset().top},1000);
			});
		});
</script>
<!--//end-smoth-scrolling-->

</head>
<body>
	<!--header-->
	<div class="header">
		<div class="container">
			<div class="header-class">
				<h1 style="color:white;"></a>CS284</a></h1>
			</div>
		</div>	
	</div>
	<!--//header-->
	<!--report-->
	<div class="report">
		<div class="container">
			<div class="fav-app">
				<h3>Reprot of Project 1: Rasterizer</h3>
				<h5 style="font-size:18px;">Han Wang</h5>				
				<h6>Submitted on Feb 17, 2022</h6>
				<div class="sngl-img">
					<img src="images/first.png" class="img" /> </a>
				</div>
				<h6>The first image I've ever rendered in my life. Produced by forgetting clear color buffer<h6>
				
				<h4>Overview</h4>
				<p style="font-size:20px;">In this project, I started with the most basic rasterization of triangles. Based on that I implemented several trick learnt from class, including supersample, transforms, Barycentric coordinates and texture mappings. Though the idea of these tricks are straight forward, the most difficult part for me is that I underestimate the difficulty to get myself familiar with C++ and new IDE. Once I was ready enough to tell the code structure and data(parameter) flows, the rest of coding work is more smooth than I thought. My overall thought on this is that implementation is always harder than it looks like.</p>
				

				<h4>Task 1: Drawing Single-Color Triangles</h4>


				<p style="font-size:20px;"><b>Walk through how you rasterize triangles in your own words.</b><br><br>
				The first implementation I used <code>width</code> and <code>height</code> as sampling boundaries, which meant that for each triangle shape every pixel in the entire framebuffer had to be sampled. It took more that three seconds to render the <I>basic/test2.svg</I>. I improved that by using the box boundary of the triangle as the sampling boundary and the rendering efficiency improved significantly.<br><br>
				I implemented the <code>inside()</code> function to detect if each sampled point is within the triangle boundary. I avoided the clockwise judgment by determining whether the symbols of the three line equition tests are equal (i.e. return <code>true</code> if all <=0 or >=0). If it returns <code> true </code> to <code>rasterize_triangle()</code>, the later will call <code>fill_pixel()</code> to the currently sampling pixel with given color.<br><br>

				<b>Explain how your algorithm is no worse than one that checks each sample within the bounding box of the triangle.</b><br><br>
				Bounding box is what I'm using. Incremental traversal should be faster than it theoretically since there are less pixel to be scanned, or maybe not since there are more if condition to determine the changing boundary. My guess is that it would probably be faster if it started at an obtuse angle instead of an acute angle.<br><br>

				<b>Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel inspector centered on an interesting part of the scene.</b><br><br>
	

				</p>

				<div class="sngl-img">
					<img src="images/task1_test4.png" class="img"/> </a>
				</div>
				<h5>basic/test4.svg with the default viewing parameters<h5>


				<h4>Task 2: Antialiasing by Supersampling</h4>


				<p style="font-size:20px;"><b>Walk through your supersampling algorithm and data structures. Why is supersampling useful?</b><br><br>
				In short, supersample divides each pixel into multiple subpixels, samples each subpixel and takes the average color as the pixel color.  It works because it removes frequencies above Nyquist before sampling.<br><br> 

				<b>What modifications did you make to the rasterization pipeline in the process? Explain how you used supersampling to antialias your triangles.</b><br><br>
				
				I think it is inefficient to sample a higher resolution image into <code>sample_buffer</code> and resolve it into <code>frame_buffer</code> in terms of memory management. So, after confirming there's no overlapping triangles in the svgs of this project (by counting the sampled time of each pixel except boundary), I added two layers of loops directly into task1 implementation as shown in the figure below.<br><br>

				However, although this four loop method works fine in <I>test4.svg</I>, it leads to the white line bug in other tasks which is widely discussed in Piazza. After double checked the correctness of all index but the bug was there, I tried to use a high resolution sample buffer and resolve it to frame buffer. Then the white lines disappear. <br><br>

				So in the end of story, I use sampled a higher resolution sample buffer and down sample it in <code>RasterizerImp::resolve_to_framebuffer()</code>, but I didn't use exactly the method in the instruction since I keep the four loop structure and fill the pixel at corresponding position: <code>fill_pixel(x * sqrt(sample_rate) + i, y * sqrt(sample_rate) + j, color)</code>.
				</p>
				

				<div class="sngl-img">
					<img src="images/task2_4loops.png" class="img"/> </a>
				</div>
				<h5>subloops for supersampling<h5>

				<p style="font-size:20px;"> In the too sub-loop of each pixel, the sampled color of <code>sample_rate</code> subpixels are added up and taken average as the color of belonged pixel in <code>RasterizerImp::resolve_to_framebuffer()</code>.</p>

				<p style="font-size:20px;"><b>Show png screenshots of basic/test4.svg with the default viewing parameters and sample rates 1, 4, and 16 to compare them side-by-side. Position the pixel inspector over an area that showcases the effect dramatically; for example, a very skinny triangle corner. Explain why these results are observed.</b><br><br>
				
				The demo with <code>sample_rates=1,4,16</code> are shown below. As the sampling rate increases, in each pixel on the edge, the proportion of subpixels for which the <code>inside()</code> function returns <code>true</code> tends to be closer and closer to the proportion of the pixel area occupied by the triangle, which leads to a more reasonable shape of color on the edge.
				</p>

				<div class="sngl-img">
					<img src="images/task2_1test4.png" class="img"/> </a>
				</div>
				<h5>basic/test4.svg <code>sample_rate=1</code><h5><br><br>
				<div class="sngl-img">
					<img src="images/task2_4test4.png" class="img"/> </a>
				</div>
				<h5>basic/test4.svg <code>sample_rate=4</code><h5><br><br>
				<div class="sngl-img">
					<img src="images/task2_16test4.png" class="img"/> </a>
				</div>
				<h5>basic/test4.svg <code>sample_rate=16</code><h5>




				<h4>Task 3: Transforms</h4>


				<p style="font-size:20px;"><b>Create an updated version of svg/transforms/robot.svg with cubeman doing something more interesting, like waving or running. Feel free to change his colors or proportions to suit your creativity. Save your svg file as my_robot.svg in your docs/ directory and show a png screenshot of your rendered drawing in your write-up. Explain what you were trying to do with cubeman in words.</b><br><br>

				I give the cubeman a push and it is falling down. Also as you can see I give it a <del>IKEA</del> Berkeley gear suit.</p>
				
				<div class="sngl-img">
					<img src="images/task3_myRobot.png" class="img"/> </a>
				</div>
				<h5>Cubeman falling down with gear suit</code><h5>


				<h4>Task 4: Barycentric Coordinates</h4>


				<p style="font-size:20px;"><b>Explain barycentric coordinates in your own words and use an image to aid you in your explanation. One idea is to use a svg file that plots a single triangle with one red, one green, and one blue vertex, which should produce a smoothly blended color triangle.</b><br><br>
 				
 				I think Barycentric coordinates is like a watercolor palette. When you put a drop of watercolor on each of the three vertices of the triangle, they will spread from the vertices to the center. The color of each point on the palette is the color of the three vertices mixed in different proportions
				</p>
				


				
				<div class="sngl-img">
					<img src="images/task4_triangle.png" class="img"/> </a>
				</div>
				<h5>Barycentric colored triangle with RGB on each vertices</h5><br><br>

				<div class="sngl-img">
					<img src="images/task4_palette.jpeg" class="img"/> </a>
				</div><br>
				<h5>Palette</code></h5>

				<p style="font-size:20px;"><b>Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1. If you make any additional images with color gradients, include them.</b></p>

				<div class="sngl-img">
					<img src="images/task4_circle.png" class="img"/> </a>
				</div>
				<h5>basic/test7.svg with default viewing parameters and sample rate 1</code></h5>


				<h4>Task 5: "Pixel sampling" for texture mapping</h4>

				
				
				
				<p style="font-size:20px;"><b>Explain pixel sampling in your own words and describe how you implemented it to perform texture mapping. Briefly discuss the two different pixel sampling methods, nearest and bilinear.</b><br><br>


				In the sampling process, we need to obtain the color of a pixel point by mapping the coordinates of the pixel point in the screen space to the texture space. Therefore we want the color to be defined continuously in texture space, so that each pixel point can get the color at the corresponding mapped coordinates. However, colors are defined discrete on the set of integers in texture space, so we need to associate points in texture space that are not defined with colors to points that are defined with colors, and that is what pixel sampling works on.</b><br><br>

				Nearest sampling is to take the color of the nearest defined point as the color of the undefined point, and Bilinear sampling is to weight the colors of the nearest integer points according to their distances. Bilinear sampling is a weighted average of the colors of the nearest integer points based on distance.</b><br><br>

				To implement pixel sammpling, I calculated the continuous (u,v) coordination with Barycentric coordination in <code>rasterize_textured_triangle()</code> and passed it to corresponding pixel sampling method. For nearest sampling, I <code>round()</code> the continuous (u,v) coordination to the nearest integral in <code>Texture::sample_nearest()</code>. For bilinear sampling, I find the nearest multiple integral (u,v) nodes with <code>floor()</code> and <code>ceil()</code>. Then I calculate the weighted average color with an inine linear interpolation function <code>lerp()</code>. </b><br><br>



								
				<b>Check out the svg files in the svg/texmap/ directory. Use the pixel inspector to find a good example of where bilinear sampling clearly defeats nearest sampling. Show and compare four png screenshots using nearest sampling at 1 sample per pixel, nearest sampling at 16 samples per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel.</b><br><br>

				</p>

				<div class="sngl-img">
					<img src="images/task5_near1.png" class="img"/> </a>
				</div><br>
				<h5>Nearest sampling at 1 sample per pixel</h5><br><br>
				<div class="sngl-img">
					<img src="images/task5_near16.png" class="img"/> </a>
				</div><br>
				<h5>Nearest sampling at 16 sample per pixel</h5><br><br>

				<div class="sngl-img">
					<img src="images/task5_bi1.png" class="img"/> </a>
				</div><br>
				<h5>Bilinear sampling at 1 sample per pixel</h5><br><br>

				<div class="sngl-img">
					<img src="images/task5_bi16.png" class="img"/> </a>
				</div><br>
				<h5>Bilinear sampling at 16 sample per pixel</h5>

				<p style="font-size:20px;"><b>Comment on the relative differences.</b><br><br>

				Compared with nearest sampling, the color change between pixels of bilinear sampling is more moderate. bilinear sampling The smaller color gap between adjacent pixels makes the overall image smoother.<br><br>

				<b>Discuss when there will be a large difference between the two methods and why.</b><br><br>
				This difference becomes more significant when the image resolution is lower and the sampling rate is lower.This difference becomes more significant when the image resolution is lower and the sample rate is lower, since a lower resolution means fewer pixels are used to transition between two different color pixels, and lower sample rate sharpen the color change.
				</p>


				<h4>Task 6: "Level sampling" with mipmaps for texture mapping</h4>
							
				
				<p style="font-size:20px;"><b>Explain level sampling in your own words and describe how you implemented it for texture mapping.</b><br><br>

				Sampling the entire image at the same level may result in distant texture aliasing or near texture over blurred. Therefore, different parts of the same image need different levels of down sampling of texture. Level sampling is done by evaluating the required mipmap level (which is essentially the down sampling level) for each part of the image and sampling from the corresponding mipmap.
				
				For implementation, <code>rasterize_textured_triangle()</code> collected the pixel sampling and level sampling method parameters <code>psm, lsm</code> and store them into the sample parameter collection <code>sp</code>. Together with sampling methods parameters, the (u,v) barycentric coordinates of (x,y)(x,y), (x+1,y)(x+1,y), and (x,y+1)(x,y+1) are also calculated in <code>rasterize_textured_triangle()</code> and stored in <code>sp</code>. The <code>sp</code> is passed to <code>Texture::sample()</code>. Selected sampling method are called in <code>Texture::sample()</code> with the desire mipmap level feedback from <code>Texture::get_level()</code>.

				<br><br>

				<b>You can now adjust your sampling technique by selecting pixel sampling, level sampling, or the number of samples per pixel. Describe the tradeoffs between speed, memory usage, and antialiasing power between the three various techniques.</b><br><br>

				<b>Supersampling</b><br><br>
				
				&nbsp &nbsp &nbsp &nbsp<b>Memory usage</b> &nbsp &nbsp Supersampling requires at least four times memory space than regular sampling, and rises as the sampling rate increases.<br><br>

				&nbsp &nbsp &nbsp &nbsp<b>Speed</b> &nbsp &nbsp Supersampling requires multiple samples per pixel, which causes a reduction in sampling speed. luckily, supersampling for each pixel can be computed in parallel, so the speed reduction can be mitigated if the amount of GPU core supports it.<br><br>

				&nbsp &nbsp &nbsp &nbsp<b>Anti-aliasing</b> &nbsp &nbsp The anti-aliasing effect of supersampling becomes more pronounced as the sampling rate increases. A disadvantage of supersampling compared to the other two sampling methods is that it does not make use of information from texture space mapping.<br><br>

				<b>Pixel sampling</b><br><br>

				&nbsp &nbsp &nbsp &nbsp<b>Memory usage</b> &nbsp &nbsp Pixel sampling does not require an expanded sample buffer like supersampling, nor does it require a pre-stored mipmap, so the pressure on memory should be the lowest of the three methods.<br><br>

				&nbsp &nbsp &nbsp &nbsp<b>Speed</b> &nbsp &nbsp Pixel sampling reduces the sampling speed. Bilinear sampling is slower than nearest sampling. This is because nearest sampling only needs to find the nearest point once for each pixel, while bilinear sampling needs to find it four times and perform multiple linear interpolations.<br><br>

				&nbsp &nbsp &nbsp &nbsp<b>Anti-aliasing</b> &nbsp &nbsp Compared to supersampling, pixel sampling takes advantage of texture space information. But based on intuitive observation it doesn't outperform supersampling. Bilinear sampling is stronger than nearest, especially when the image resolution is smaller.<br><br>

				<b>Level sampling</b><br><br>
				
				&nbsp &nbsp &nbsp &nbsp<b>Memory usage</b> &nbsp &nbsp Due to mipmap, the memory usage of level sampling is larger than that of regular sampling. However, compared to supersampling, the memory usage of level sampling is lower.<br><br>
				
				&nbsp &nbsp &nbsp &nbsp<b>Speed</b> &nbsp &nbsp On top of pixel sampling, level sampling furtherly increases the time to calculate mipmap level and interpolate between multiple mimap levels (if trilinear).<br><br>
				
				&nbsp &nbsp &nbsp &nbsp<b>Anti-aliasing</b> &nbsp &nbsp When there are different depth-of-field levels in the image, level sampling is significantly better than the other two methods. It makes full use of texture space information to calculate desired downsampling level for different depth-of-field regions.<br><br>

		

				<b>Using a <I>png</I> file you find yourself, show us four versions of the image, using the combinations of <code>L_ZERO</code> and <code>P_NEAREST</code>, <code>L_ZERO</code> and <code>P_LINEAR</code>, <code>L_NEAREST</code> and <code>P_NEAREST</code>, as well as <code>L_NEAREST</code> and <code>P_LINEAR</code></b><br><br>

				</p>

				<div class="sngl-img">
					<img src="images/task6_PNLZ.png" class="img"/> </a>
				</div><br>
				<h5><code>L_ZERO, P_NEAREST</code></h5><br><br>

				<div class="sngl-img">
					<img src="images/task6_PLLZ.png" class="img"/> </a>
				</div><br>
				<h5><code>L_ZERO, P_LINEAR</code></h5><br><br>

				<div class="sngl-img">
					<img src="images/task6_PNLN.png" class="img"/> </a>
				</div><br>
				<h5><code>L_NEAREST, P_NEAREST</code></h5><br><br>

				<div class="sngl-img">
					<img src="images/task6_PLLN.png" class="img"/> </a>
				</div><br>
				<h5><code>L_NEAREST, P_LINEAR</code></h5><br><br>
				
	<!--//report-->
	










	<!--smooth-scrolling-of-move-up-->
		<script type="text/javascript">
			$(document).ready(function() {
				/*
				var defaults = {
					containerID: 'toTop', // fading element id
					containerHoverID: 'toTopHover', // fading element hover id
					scrollSpeed: 1200,
					easingType: 'linear' 
				};
				*/
				
				$().UItoTop({ easingType: 'easeOutQuart' });
				
			});
		</script>
		<a href="#" id="toTop" style="display: block;"> <span id="toTopHover" style="opacity: 1;"> </span></a>
	<!--//smooth-scrolling-of-move-up-->	
</body>
</html>
