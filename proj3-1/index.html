<html>
<head>
<title>cs284-p3-1</title>
<link href="css/style.css" type="text/css" rel="stylesheet" media="all">
<link href="css/bootstrap.css" type="text/css" rel="stylesheet" media="all">

<!-- js -->
<script src="js/jquery.min.js"></script>
<script src="js/modernizr.custom.js"></script>
<!-- //js -->	
<!-- start-smoth-scrolling-->

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>
<script type="text/javascript" src="js/move-top.js"></script>
<script type="text/javascript" src="js/easing.js"></script>	
<script type="text/javascript" src="js/modernizr.custom.53451.js"></script>
<script type="text/javascript">
		jQuery(document).ready(function($) {
			$(".scroll").click(function(event){		
				event.preventDefault();
				$('html,body').animate({scrollTop:$(this.hash).offset().top},1000);
			});
		});
</script>
<!--//end-smoth-scrolling-->

</head>
<body>
<!-- <body oncontextmenu='return false' ondragstart='return false' onselectstart ='return false' onselect='document.selection.empty()' oncopy='document.selection.empty()' onbeforecopy='return false' onmouseup='document.selection.empty()'> -->
	<!--header-->
	<div class="header">
		<div class="container">
			<div class="header-class">
				<h1 style="color:white;"></a>CS284</a></h1>
			</div>
		</div>	
	</div>
	<!--//header-->
	<!--report-->
	<div class="report">
		<div class="container">
			<div class="fav-app">
				<h3>Reprot of Project 3-1: Path Tracing</h3>
				<h5 style="font-size:18px;">Han Wang</h5>				
				<h6>Submitted on Mar 28, 2022</h6>
				<div class="sngl-img">
					<img src="images/first.png" class="img" /> </a>
				</div>
				<h6>Bug Art: Zebra-Cow generated by wrong intersection test return.<h6>
				
				<h4>Overview</h4>
				<p style="font-size:20px;">In this project I have implemented the core components of a ray tracing based 3D renderer. The first component is the generation of camera rays and their intersection detection with objects. To improve the detection efficiency, the BVH algorithm was implemented to efficiently remove a large number of rays that do not intersect with BVH. A heuristic splitting method was applied to BVH to improve the fit of the boundary box to the model. In the next section, direct illumination and global illumination are implemented based on Monte Carlo integration. Eventually, adaptive sampling is implemented to improve the efficiency of sampling computation by setting early termination according to the convergence rate of each pixel point.
				
				</p><br><br>

				<h4>Part 1: Ray Generation and Scene Intersection</h4>


				<p style="font-size:20px;"><b>Walk through the ray generation and primitive intersection parts of the rendering pipeline. Explain the triangle intersection algorithm you implemented in your own words.</b><br><br>

				As the first step in the path tracing renderer implementation, <code>Camera::generate_ray</code> serves to cast rays along a normalized direction vector from the camera position in the world space coordinates. The generated Ray is passed to <code>PathTracer::raytrace_pixel</code>, which takes unnormalized pixel coordinates as input to collect samples on the corresponding position on image. <code>PathTracer::est_radiance_global_illumination()</code> was implemented to conduct the radiance estimator for the Monte Carlo estimation.

				After the ray generation, the intersection detection of ray-triangle and ray-surface was implemented in <code>Triangle::has_intersection(),intersect()</code> and <code>Sphere::has_intersection(),intersect()</code> The existence of an intersection is determined by comparing whether the t ,or one of the t for sphere, lies between min_t and max_t. For the sphere where both solutions of the quadratic equation are in range, the smaller root will be kept as t_value. For existing intersection points, their t-value, surface normal, points to the primitive and BSDF are stored in the isect structure.


				<br><br>

				<b>Show images with normal shading for a few small .dae files.</b><br><br>

				

				<div class="div1">
					<img src="images/P1_banana.png" /> </a>
				</div>
				<div class="div1">
					<img src="images/P1_bunny.png" /> </a>
				</div>
				<h5>Normal Shading Instances</h5>






				<h4>Part 2: Bounding Volume Hierarchy</h4>


				<p style="font-size:20px;"><b>Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.</b><br><br>


				To increase the speed of tracing, eliminating the rays that not intersect with object in current view is a valid approach. To efficiently achieve that, the bounding volume hierarchy(BVH) is applied, which is essentially a binary tree of which the nodes store the bounding boxes and hierarchically connected to its left and right child. In the application in this project, the BVH is implemented in <code>BVHAccel:construct_bvh()</code>. For each bounding box of each nodeï¼Œfor three centroids of primitives on x,y and z axis, the one with the lowest production of surface area of the resulting child node bounding box multiplied by the number of primitives in each child node is selected as the splitting point.

				Similar to the triangle and sphere, the intersection detection of ray-BVH was implemented in <code>BVHAccel::has_intersection(),intersect()</code>. By eliminating the rays that are not intersected with BVH from tracing iteration, the rendering speed could be improved. Compared with the simple dichotomous method, the heuristic approach implemented for the splitting point determining can make the boundary box of BVH fit the target model more closely, so that the number of rays intersecting the BVH but not the model can be reduced, thus further improving the efficiency.<br><br>

				<b>Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.</b><br><br></p>
				<div class="div1">
					<img src="images/P2_maxplanck.png" /> </a>
				</div>
				<h5>Max Plank Rendered in 1.96s with GUI, BVH traced 117069 rays</h5>
				<div class="div1">
					<img src="images/P2_CBlucy.png" /> </a>
				</div>
				<h5>P2_CBlucy Rendered in 3.14s with GUI, BVH traced 153906 rays</h5><br><br>

				<p style="font-size:20px;"><b>Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.</b><br><br></p>
				<div class="div1">
					<img src="images/P2_render_time.png" /> </a>
				</div>
				<h5>Rendering time efficiency comparison: with and without BVH acceleration</h5><br><br>

				<p style="font-size:20px;">
				<h4>Part 3: Direct Illumination</h4>



				<p style="font-size:20px;"><b>Walk through both implementations of the direct lighting function.</b><br><br>
				
				The direct illumination is implemented in <code>PathTracer::estimate_direct_lighting_importance()</code>. To test the implementation, a diffuse material was designed in <code>DiffuseBSDF::f</code>. When the camera ray generated in Part 1 intersects an object, the bi-directional radiance distribution function (BRDF) of the object surface and the radiance reaching the intersection determine the radiance observed by the camera away from this intersection. Monte Carlo estimation generates multiple fleeting rays from the intersection and retains the rays among them that reach the light source and are not obstructed. <br><br>

				Two different approached are applied to generate the fleeting rays from intersection for direct illumination implementation: sampling uniformly in a hemisphere around each intersection and importance sampling. The advantages of important sampling over uniform sampling is the generated rays are bounded to the light sources direction and only discounted if they are obstructed, via which we can get a better lighting effect with the same number of samples

				<br><br></p>

				<p style="font-size:20px;"><b>Show some images rendered with both implementations of the direct lighting function.<br><br></p>

				<div class="div1">
					<img src="images/P3_bunny_H_1_32.png" /> </a>
				</div>
				<h5>Uniform Sampling: <code> -s 1 -l 64</code></h5><br><br>

				<div class="div1">
					<img src="images/P3_bunny_1_32.png" /> </a>
				</div>
				<h5>Importance Sampling: <code> -s 1 -l 64</code></h5><br><br>




				<p style="font-size:20px;"><b>Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
				The comparison of uniform hemisphere sampling and importance sampling with different sample rates are shown below<br><br></p>

				<div class="div1">
					<img src="images/P3_CBspheres_1_1.png" /> </a>
				</div>
				<h5>Importance Sampling:<code> -s 1 -l 1</code></h5><br><br>
				<div class="div1">
					<img src="images/P3_CBspheres_1_4.png" /> </a>
				</div>
				<h5>Importance Sampling:<code> -s 1 -l 4</code></h5><br><br>

				<div class="div1">
					<img src="images/P3_CBspheres_1_16.png" /> </a>
				</div>
				<h5>Importance Sampling:<code> -s 1 -l 16</code></h5><br><br>

				<div class="div1">
					<img src="images/P3_CBspheres_1_64.png" /> </a>
				</div>
				<h5>Importance Sampling:<code> -s 1 -l 64</code></h5><br><br>



				<h4>Part 4: Global Illumination</h4>


				<p style="font-size:20px;"><b>Walk through your implementation of the indirect lighting function.</b><br><br>
				In this part the global illumination is implemented to take the contribution of the ray reflection from the objects that are not emitting lights to the overall illumination. Compared with direct illumination considering once reflection from light source, the global illumination takes all the possible path with multiple reflections into consideration.<br><br> 

				The global illumination is implemented in <code> PathTracer::est_radiance_global_illumination()</code> by adding the bounce radiance returned from <code>at_least_one_bounce_radiance()</code> to the direct illumination radiance. Once the ray intersected with a object, other than the contribution from direct illumination, there will be several flexibility rays generated from the intersection with randomly sampled directions. If the generated ray reach another object, the same iteration will be conducted at the new intersection. To avoid infinite reflection crashes the calculation, there's a Russian Roulette implemented to provide probability to terminated current reflection when a ray intersects with object and before new fleeting ray generated. <br><br></p>

				<p style="font-size:20px;"><b>Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel. Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)</b><br><br>
				
				<div class="div1">
					<img src="images/P4_only_D.png" /> </a>
				</div>
				<h5>Only Direct Illumination:<code> -s 1024 -l 16</code></h5><br>

				<div class="div1">
					<img src="images/P4_only_inD.png" /> </a>
				</div>
				<h5>Only Indirect Illumination:<code> -s 1024 -l 16</code></h5><br>

				<div class="div1">
					<img src="images/P4_DinD.png" /> </a>
				</div>
				<h5>Direct and Indirect Illumination:<code> -s 1024 -l 16</code></h5><br>

				<p style="font-size:20px;"><b>For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.</b><br><br>

			

				<div class="div1">
					<img src="images/P4_m1.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -m 1</code></h5><br>		

				<div class="div1">
					<img src="images/P4_m2.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -m 2</code></h5><br>				

				<div class="div1">
					<img src="images/P4_m3.png" /> </a>
				</div>
				<h5>Only Direct Sampling:<code> -m 3</code></h5><br>		

				<div class="div1">
					<img src="images/P4_m100.png" /> </a>
				</div>
				<h5>Only Direct Sampling:<code> -m 100</code></h5><br>				


				<p style="font-size:20px;"><b>Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays</b><br><br>


				<div class="div1">
					<img src="images/P4_s1.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 1</code></h5><br>				

				<div class="div1">
					<img src="images/P4_s2.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 2</code></h5><br>				


				<div class="div1">
					<img src="images/P4_s4.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 4</code></h5><br>				


				<div class="div1">
					<img src="images/P4_s8.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 8</code></h5><br>				


				<div class="div1">
					<img src="images/P4_s16.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 16</code></h5><br>				


				<div class="div1">
					<img src="images/P4_s64.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 64</code></h5><br>				


				<div class="div1">
					<img src="images/P4_s1024.png" /> </a>
				</div>
				<h5>CBbunny.dae:<code> -s 1024</code></h5><br>				

	




				<h4>Part 5: Adaptive Sampling</h4>
			
				
				<p style="font-size:20px;"><b>Walk through your implementation of the adaptive sampling.</b><br><br>
				To further improve the sampling efficiency, we should perform a sampling rate appropriate to each pixel. adaptive sampling aims to determine when to stop sampling based on the convergence rate of each pixel. Pixels with fast convergence rates can be sampled earlier to improve sampling efficiency. For slow converging pixels, a higher sampling rate should be applied to reduce noise.<br><br>

				The adaptive sampling is implemented in <code>PathTracer::raytrace_pixel()</code>. For certain interval of iteration of each pixel sampling, <code>samplesPerBatch</code>, the termination condition will be checked by determining if the variable:
				<div class="div1">
					<img src="images/P5_id.png" /> </a>
				</div>


			</p>

				<p style="font-size:20px;"><b>Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.</b><br><br>
				
				<div class="div1">
					<img src="images/P5_s2048.png" /> </a>
				</div>
				<h5>Adaptive Sampling: <code> -s 2048 -l 1 -m 6</code></h5><br><br>	

				<div class="div1">
					<img src="images/P5_s2048_rate.png" /> </a>
				</div>
				<h5>Samplerate</code></h5><br><br>








				
				
	<!--//report-->
	










	<!--smooth-scrolling-of-move-up-->
		<script type="text/javascript">
			$(document).ready(function() {
				/*
				var defaults = {
					containerID: 'toTop', // fading element id
					containerHoverID: 'toTopHover', // fading element hover id
					scrollSpeed: 1200,
					easingType: 'linear' 
				};
				*/
				
				$().UItoTop({ easingType: 'easeOutQuart' });
				
			});
		</script>
		<a href="#" id="toTop" style="display: block;"> <span id="toTopHover" style="opacity: 1;"> </span></a>
	<!--//smooth-scrolling-of-move-up-->	
</body>
</html>
